从2025年10月Sora2出来之后，中国的AI视频模型厂商集体加快研发速度，加班加点，奋力推出多个音画同型的多模态模型，从Wan2.6、PixVerse V5、Vidu Q3、Kling3.0，到Seedance2.0，才4个月时间，中国的AI视频模型无论从数量上还是质量上，又重回巅峰了。 内测时随手发的15秒视频在X上的浏览量已破十万。 ![pic_a5c96ef8.png](https://ideaflow-article-to-markdown.hf.space/images/pic_a5c96ef8.png)

# 一、Seedance2.0超全使用指南 

先整体说一下Seedance2.0的最大特点，就是全能参考。 全能参考几乎是万物可参。从文字提示词到多张图片、视频、音频都可稳定参考，还可以使用图片和视频组合参考，这种模式对个性化创作是非常友好的。 可控性高意味着艺术自由度和商业价值高。 另外一个突出的特点就是Seedance2.0的多模态能力，在稳定保持参考图片或视频的特征的同时，可以输出含有多种模态的音画视频，包含了一定的策划辅助、剪辑、配音、配乐等能力。这种多模态能力需要有强大的llm底座能力，是一种综合的大模型理解能力，不单单局限于单一的视觉影像模态。 如果非要说缺点的话，就是目前模型开放对外的分辨率还不够，但分辨率不够高这个问题迟早能被解决。跟Seedance2.0优秀的视频可控性、风格稳定性和强物理理解能力对比起来，分辨率问题可以等他们月底再解决！（催加卡） 还有一个问题是AI视频的通病，就是参考或者生成的精确度/精细度问题。例如人脸的准确参，如果是全景的人脸就容易参考不准确，以及如果生成全景就容易出现人脸或四肢崩坏或不清晰的问题。对于精品化和定制化创作来说，精细度是蛮重要的，追求精度的造价高，目标客户少，所以不是模型升级的优先级倒也能理解，寄希望于后续算力降价能把精度追上。

## （一）使用方法： 

你可以在即梦网页版或者小云雀使用，估计后续豆包也会上线，毕竟都是字节旗下产品。 即梦：https://jimeng.jianying.com/ 小云雀：https://xyq.jianying.com/ ![pic_dfd69c20.png](https://ideaflow-article-to-markdown.hf.space/images/pic_dfd69c20.png) ![pic_ee7c65c4.png](https://ideaflow-article-to-markdown.hf.space/images/pic_ee7c65c4.png) ![pic_f750fecb.png](https://ideaflow-article-to-markdown.hf.space/images/pic_f750fecb.png) 目前即梦已经全量上线每15秒花费90积分，小云雀官网免费使用3次但有水印。

<table> 
 <thead> 
  <tr> 
   <th><p><strong><span><span>核心维度</span></span></strong></p></th> 
   <th><p><strong><span><span>Seedance 2.0&nbsp;</span></span></strong></p></th> 
  </tr> 
 </thead> 
 <tbody> 
  <tr> 
   <td><p><strong><span><span>图片输入</span></span></strong></p></td> 
   <td><p><strong><span><span>≤ 9 张</span></span></strong></p></td> 
  </tr> 
  <tr> 
   <td><p><strong><span><span>视频输入</span></span></strong></p></td> 
   <td><p><strong><span><span>≤ 3 个，总时长不超过15s</span></span></strong></p><p><span><span>（有参考视频会贵一点哦）</span></span></p></td> 
  </tr> 
  <tr> 
   <td><p><strong><span><span>音频输入</span></span></strong></p></td> 
   <td><p><strong><span><span>支持 MP3 上传，数量≤ 3 个，总时长不超过15s</span></span></strong></p></td> 
  </tr> 
  <tr> 
   <td><p><strong><span><span>文本输入</span></span></strong></p></td> 
   <td><p><strong><span><span>自然语言</span></span></strong></p></td> 
  </tr> 
  <tr> 
   <td><p><strong><span><span>生成时长</span></span></strong></p></td> 
   <td><p><strong><span><span>≤ 15s，可自由选择4-15s</span></span></strong></p></td> 
  </tr> 
  <tr> 
   <td><p><strong><span><span>声音输出</span></span></strong></p></td> 
   <td><p><strong><span><span>自带音效/配乐</span></span></strong></p></td> 
  </tr> 
  <tr> 
   <td colspan="2"><p><strong><span><span>交互限制：</span></span></strong><u><strong><span><span>目前支持的混合输入总上限是 12 个文件</span></span></strong></u><strong><span><span>。建议优先上传对画面或节奏影响最大的素材，合理分配不同模态的文件数量</span></span></strong></p></td> 
  </tr> 
 </tbody> 
</table>

使用方式也很简单，就是在提示框中输入文字、参考图片、参考视频、参考音频等内容，可以@相关要准确参考的音视频，选择画幅、时长，再点击生成即可。 注意图片不要超过9张，视频不要超过3个。

## （二）10种超好玩的玩法和提示词 

## 视频号总览： 

## 1、电商创意广告（参考图生） 

![pic_db5aa8e8.png](https://ideaflow-article-to-markdown.hf.space/images/pic_db5aa8e8.png) ![pic_3097e7e2.png](https://ideaflow-article-to-markdown.hf.space/images/pic_3097e7e2.png)

 *  提示词：根据@图片1的脚本生成@图片2香水产品的广告内容，旁白的声音参考自然的女声用英文读，香水的比例要注意一些，要用自然的光线融入进背景里，不要太重的贴图和抠图感，节奏可以更明快一些。

## 2、小说一键成片（文生视频） 

狂人日记片段改编 ![pic_25e3b5f5.png](https://ideaflow-article-to-markdown.hf.space/images/pic_25e3b5f5.png) ![pic_2131c4cf.png](https://ideaflow-article-to-markdown.hf.space/images/pic_2131c4cf.png) 因为两个视频效果都还不错，我就都放上来了。wyb和yhw两位老师我没垫图，提示词里也没有提到人名，粉丝老师们求不喷…… 我的文字分镜图太长了，我就没有都贴上来，大家可以参考上一条的分镜头写法，主要就是把景别和画面内容写清楚然后截图进行参考即可。 3、角色换装（参考角色生） ![pic_08bde62f.png](https://ideaflow-article-to-markdown.hf.space/images/pic_08bde62f.png) ![pic_b77b1ccf.png](https://ideaflow-article-to-markdown.hf.space/images/pic_b77b1ccf.png)

 *  提示词：我希望给这个女孩换10套不同的衣服，出现在不同的场景里，做不同的模特拍照动作，自然一点。

## 这个视频其实跟我长得不太像，也可能是我给的素材参考的问题，我直接给的一张全景钓鱼的照片，像素也不太高，所以只参考了大致造型。 

## 4、AI服装电商（参考图生） 

![pic_5da8eaf5.png](https://ideaflow-article-to-markdown.hf.space/images/pic_5da8eaf5.png) ![pic_a034abaf.png](https://ideaflow-article-to-markdown.hf.space/images/pic_a034abaf.png) ![pic_f679e784.png](https://ideaflow-article-to-markdown.hf.space/images/pic_f679e784.png) 我在X上发上一条角色变装视频的时候，一个朋友说可以换不同衣服带货，所以才又延伸了一条。只抽一次的效果基本上是可以用在电商短视频切片的，微调一下提示词和工作流应该可以商业落地。 ![pic_21e8efda.png](https://ideaflow-article-to-markdown.hf.space/images/pic_21e8efda.png)   
 不过对AI服装比较了解的朋友说目前还差一些尺寸问题，比如160、170等不同大小的尺寸对比等，在打版上需要人工细调。

## 5、AI科普/宣传/MG动画视频（参考图生） 

![pic_1354fb09.png](https://ideaflow-article-to-markdown.hf.space/images/pic_1354fb09.png) ![pic_2c8a7a6e.png](https://ideaflow-article-to-markdown.hf.space/images/pic_2c8a7a6e.png) 其实效果还蛮好的，以前需要用复杂的AE来做宣传动画，现在AI的实现确实要比手K要简单很多。

## 6、AI预告片（文生） 

![pic_01014d09.png](https://ideaflow-article-to-markdown.hf.space/images/pic_01014d09.png) Seedance2.0纯文生的话在影片风格上观感总是会比较像电视剧，或者说影片的光影层次会比较少，要在提示词里面调到有电影感的话可能需要细致地去描述画面里光影的层次以及影调等等，甚至服化道和场景也需要详细描述出来才可能能有比较好的响应。

## 7、AI武打片（参考角色生） 

![pic_717da7a3.png](https://ideaflow-article-to-markdown.hf.space/images/pic_717da7a3.png) ![pic_8d1cf92d.png](https://ideaflow-article-to-markdown.hf.space/images/pic_8d1cf92d.png) 这个片段跟上一个片段情况类似，这个模仿的是李安导演的《卧虎藏龙》，影调也是调了半天分镜的提示词才看起来不那么像一些风格扁平的电视剧，但跟电影本身的质感还是有些差距，只是现阶段能做到这个程度，对于AI视频来说已经是巨大的进步了。 8、AI多宫格漫画（参考图生） ![pic_7ec8bada.png](https://ideaflow-article-to-markdown.hf.space/images/pic_7ec8bada.png) ![pic_217bc81b.png](https://ideaflow-article-to-markdown.hf.space/images/pic_217bc81b.png) 这个测试片段用的是我非常喜欢的漫画《忒修斯之船》作为参考，生成的效果还不错，我感觉漫画版权商可以批量生产动漫了，只是对于传统动画行业来说，真的是沉重的打击……

## 9、AI动画片（参考角色生） 

![pic_83ff8c1b.png](https://ideaflow-article-to-markdown.hf.space/images/pic_83ff8c1b.png)

 *  提示词：小鸡 睁开眼睛。小鸡 在白色的房间跳了起来。小鸡 往前冲。小鸡跑的鸡爪子。小鸡 的面前出现一只黑熊。小鸡 转身跑，黑熊在小鸡背后跟着跑。   
    

小鸡视频是我测试的第一条Seedance2.0，出得非常随意和快，但效果却出奇地好。 10、AI故事片——角色场景一致性（参考图生） ![pic_03f4f4e8.png](https://ideaflow-article-to-markdown.hf.space/images/pic_03f4f4e8.png) ![pic_209ee3aa.png](https://ideaflow-article-to-markdown.hf.space/images/pic_209ee3aa.png) 这个片段老实说我也做得很快，不到一个小时吧，抽了三段15秒剪辑的，主要是为了测试人物和场景的保持和连贯，因为我还没找到除了后期配音可以比较好保持音频连贯的方法，就还没出到对话部分，但做分镜真的比以前容易很多了。 但精细化还是需要多修改抽卡！ 还有一些其他的功能如使用多图参考去输出长镜头，视频延长功能、视频编辑修改功能，其实都是基于Seedance2.0的多模态能力，因为视频模型足够智能，能听得懂指令，可以富有想象力地去补充、扩充、修改视频内容，所以我们只需要用自然语言去描述你想要呈现和修改的内容即可。 持续修改和制作调整考验的是耐心和审美选择。 其实C端用户与模型交流的提示词并没有那么神秘，关键点在于你能清晰且准确地描述出你的需求和想象画面即可。

# 二、技术门槛降低，创作者将何去何从 

因为AI技术的变化太快了，谁也不敢说一直能稳居宝座，毕竟竞争非常激烈，最好用的模型一直在产生变化。 最强宝座一直是国内外各家视频模型轮流坐，Seedance2.0的领先咱也只敢说是在此时此刻的当下，因为不知道还有哪家准备再发货。 但很久没有哪家视频模型的更新会像2026年2月6日的晚上一样，让已经在AI视频领域沉浸了3年的创作者感到如此恐慌。 哪怕Sora2的更新都没有让人感到这么心慌。 因为Sora2还是有一定的使用门槛，毕竟使用需要魔法、高昂的费用，以及复杂的提示词用法，这些原因拦住了大部分用户。可Seedance2.0大幅度地降低了使用门槛，从成本到使用方法都要比Sora2便宜和简单，只要一句话或一张图就能快速成片，效果还不差。 C端如此，更不要说那些藏起来的、还没对外发布的、专门为了B端市场服务的、普通用户暂且还用不到的视频模型，进化程度如何了。 有人兴奋，有人慌张。 兴奋是AI视频的技术终于有了可见的落地能力，几乎不用再考虑如何才能适应AI的技术边界，只要考虑你脑海中的画面和故事就好。 慌张是技术门槛的降低意味着对创作者提出了更高的要求，现有的知识储备和审美认知可能还远远不够。 没有系统学过视听语言和故事写作的用户，也可以借助AI快速产出视觉效果还不错的画面，那专业创作者的优势又会在哪呢？ 如果你想创作出与众不同的内容，意味是你需要花费更多的时间精力去试错、去学习、去尝试独特的视觉表达，慌张和绝望的底层原因可能来自这里。 更深层的恐慌是，害怕自己并没有艺术上的天赋，你原本所获得的掌声和青睐可能只是由于信息差和技术门槛造成的。 早期AI视频创作形态的泡沫在此刻破灭，真正的竞技场才刚刚开始。 我始终相信，洗牌技术，留下表达，应该不是一件坏事。 创意、创作、表达，这些事情本来就是很抽象且无法量化的。溯其本源，实际上是来自一种创作冲动，这种冲动会带你去触达和学习所有路径。 我相信任何一个行业也都是这样，对这个行业本身的热爱和憧憬会让你排除万难，找到适合自己的成长模式。 人类的情感，或许是面对AI袭来时，最强有力的秘密武器。因为珍贵的生命体验，你是独一份的。 我几乎所有的创作来源都可以在我的生命体验里找到真实坐标，你要相信你最真实的情感会穿透提示词、穿透影像、穿透屏幕，抵达和你一样真实的人的内心。 独特是同质化的解药。感受自己的情感，感受和家人朋友的关系，感受世间万物的一切，把自己的独特感受用影像表达出来，或许是技术之外，我们可以掌控的部分。 以及其实喜欢创作的人并没有我们想象的多，因为这件事情太痛苦了，精神负担也要比想象的重很多，投入和产出回报并不能成正比。 大部分人还是更喜欢听别人讲故事，而不是制作故事。 所以也不用过于恐慌，因为愿意做苦行僧的可能只有少部分真正对创作感兴趣的人…… 后续会涌现的各路大神，也是那些原本就对创作感兴趣但苦于没有学习通道的人。   
 对于创作者来说，对手从来不是别人，技术进化不是创作枯竭的借口，也不会抹去你过去的审美积累和沉淀。 关键在于我们有没有真正用心在感受这个世界，以及不断地练习表达。   
 我们慌张，是因为可能会被更厉害的创作者和作品取代或打击。慌张也有可能是创作暂时因为AI变得“廉价”，但总有价高者，只是需要更有说服力的创意和创作能力。 不止是被误解，不断被打击也是创作者和表达者的宿命。   
 压力太大了也可以放弃，选择另一条路可能会比创作快乐。 但如果创作才是你的快乐，并且坚持下去了，也许会发现其实这一切并没有那么难。 所以，不用慌，也不用焦虑，做好当下手头能做的事情就可以。 最重要的是，要少熬夜，保持健康。   
 文章的最后，感谢奋战在一线的AI开发者和从业者，你们创造了如此多好用的工具，在激烈的中美AI大战中持续坚守，让创作者和用户的想象力得以无限延伸！

最后的最后，如果你喜欢我的分享的话，感谢你的点赞、转发、评论、一键三连！你的鼓励将会成为我创作的动力，笔芯！